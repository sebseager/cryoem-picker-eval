{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from collections import OrderedDict\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')  # so we can show figures in the notebook\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# imports from ../scripts directory\n",
    "sys.path.append(os.path.abspath(os.path.join(\"..\", \"scripts\")))\n",
    "from common import *\n",
    "from consts import *\n",
    "from coord_converter import star_to_df\n",
    "from build_corrs import fill_upper_triangle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"GT Classes\", \"GT\", \"Consensus\"]  # MUST match order of inputs passed to build_corrs.py\n",
    "gt_name = \"GT Classes\"\n",
    "n_max_classes = 400\n",
    "score_clip = None  # or some tuple like (0, 1)\n",
    "\n",
    "scores_dir = Path(\"~/Desktop/imppel_fig4_data/n40_test\").expanduser()\n",
    "out_dir = Path(\"~/Desktop/imppel_fig4_data/n40_test\").expanduser()\n",
    "data_dir = Path(\"~/Desktop/imppel_fig4_data/src/\").expanduser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate/normalize input paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrcs_paths = [str(data_dir / Path(n).as_posix()) + \".mrcs\" for n in class_names]\n",
    "star_paths = [str(data_dir / Path(n).as_posix()) + \".star\" for n in class_names]\n",
    "mrcs_paths = [p for p in mrcs_paths if os.path.exists(p)]\n",
    "star_paths = [p for p in star_paths if os.path.exists(p)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First combine all input score .npy files into a single array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5380527eaed4846ad7eca102235773b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def combine_corr_data(data_dir):\n",
    "    out = None\n",
    "    files = glob(str(data_dir / \"scores_*.npy\"))\n",
    "    if not files:\n",
    "        log(f\"no files found in {data_dir}\")\n",
    "        return None\n",
    "    for f in tqdm(files):\n",
    "        arr = np.load(f)\n",
    "        if out is None:\n",
    "            out = arr\n",
    "        else:\n",
    "            if arr.shape == out.shape:\n",
    "                idx = np.where(~np.isnan(arr))\n",
    "                out[idx] = arr[idx]\n",
    "            else:\n",
    "                log(f\"corr data shapes do not match: {arr.shape} != {out.shape}\", lvl=2)\n",
    "                return None\n",
    "    return out.T\n",
    "\n",
    "max_scores = combine_corr_data(scores_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read input .mrcs and .star files into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b9486914b243c2a28106c7dafd8f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def read_class_avgs(mrcs_paths, star_paths, n_max_classes=None):\n",
    "    if not star_paths:\n",
    "        star_paths = [None for _ in mrcs_paths]\n",
    "\n",
    "    class_avgs = OrderedDict()\n",
    "    class_idx = 0\n",
    "    for m, s in tqdm(zip(mrcs_paths, star_paths), total=len(mrcs_paths)):\n",
    "        mrcs = read_mrc(m, mmap=True)\n",
    "        n_cls = len(mrcs) if n_max_classes is None else min(n_max_classes, len(mrcs))\n",
    "        idxs = list(range(class_idx, class_idx + n_cls))\n",
    "        class_idx = class_idx + n_cls\n",
    "        class_avgs[Path(m).stem] = {\n",
    "            \"mrcs\": mrcs[:n_cls],\n",
    "            \"star\": None if not s else star_to_df(s),\n",
    "            \"name\": Path(m).stem,\n",
    "            \"idxs\": idxs,\n",
    "        }\n",
    "\n",
    "    # reorder class avg stacks by particle distribution if STAR available\n",
    "    for stem, data in class_avgs.items():\n",
    "        if \"star\" not in data or data[\"star\"] is None:\n",
    "            continue\n",
    "\n",
    "        distr = data[\"star\"][\"_rlnClassDistribution\"].to_numpy()\n",
    "        sorted_idx = np.argsort(distr)[::-1]\n",
    "        class_avgs[stem][\"sorted_idx\"] = sorted_idx\n",
    "        class_avgs[stem][\"sorted_distr\"] = np.take_along_axis(\n",
    "            distr, sorted_idx, axis=None\n",
    "        )\n",
    "        # we use [:, None, None] to broadcast index to 3D like mrcs stack\n",
    "        class_avgs[stem][\"mrcs\"] = np.take_along_axis(\n",
    "            data[\"mrcs\"], sorted_idx[:, None, None], axis=0\n",
    "        )\n",
    "\n",
    "    return class_avgs\n",
    "\n",
    "class_avgs = read_class_avgs(mrcs_paths, star_paths, n_max_classes=n_max_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max score histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customize parameters for sample grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samp = 10\n",
    "samp_xval_ranges={\n",
    "    k: [(-0.1, 0), (0, 0.1), (0.34, 0.36), (0.39, 0.41), (0.44, 0.46)]\n",
    "    for k in class_names\n",
    "    if k != gt_name\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e6606badff495fa08f76c44bbd78be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seb/.pyenv/versions/3.7.10/lib/python3.7/site-packages/ipykernel_launcher.py:69: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n"
     ]
    }
   ],
   "source": [
    "scores = max_scores.copy()\n",
    "\n",
    "# correlations are clipped to the range indicated by score_clip\n",
    "if score_clip is not None:\n",
    "    scores = np.clip(scores, *score_clip)\n",
    "\n",
    "# select only GT-vs-rest scores\n",
    "# in mask, cells to be cleared are set to True\n",
    "l = scores.shape[0]\n",
    "gt_start, gt_end = class_avgs[gt_name][\"idxs\"][0], class_avgs[gt_name][\"idxs\"][-1] + 1\n",
    "mask = np.ones_like(scores, dtype=bool)  # make all-True mask\n",
    "mask[:, gt_start : gt_end] = False  # make GT-vs-all scores False down columns\n",
    "mask[gt_start : gt_end, :] = True  # make GT-vs-GT scores True again\n",
    "\n",
    "# apply mask to scores\n",
    "scores[mask] = np.nan\n",
    "\n",
    "\n",
    "# find max with any ground truth for each particle\n",
    "# think about the heatmap - maxes is the colmax from right to left\n",
    "#       (rightmost col first in the list, leftmost col last)\n",
    "#       so we reverse it to get it in same order as classes in class_avgs\n",
    "# ignore RuntimeWarning (nanmax throws RuntimeWarning if all scores are nan)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    try:\n",
    "        \n",
    "        maxes = np.nanmax(scores, axis=1)[::-1]\n",
    "    except ValueError:\n",
    "        raise ValueError(\"scores array empty (skipping max score histogram)\")\n",
    "\n",
    "# plot histogram\n",
    "hist_fig, hist_ax = plt.subplots(figsize=(12, 8), dpi=800)\n",
    "\n",
    "# keep track of samples for later\n",
    "samples = {k: {} for k in samp_xval_ranges.keys()}\n",
    "\n",
    "for i, pckr_name in enumerate(tqdm(class_avgs.keys())):\n",
    "    slice_start = class_avgs[pckr_name][\"idxs\"][0]\n",
    "    slice_end = class_avgs[pckr_name][\"idxs\"][-1] + 1\n",
    "    try:\n",
    "        y, edges = np.histogram(\n",
    "            maxes[slice(slice_start, slice_end)], bins=80, density=True\n",
    "        )\n",
    "    except ValueError:\n",
    "        continue  # skip all-nan slices\n",
    "    centers = 0.5 * (edges[1:] + edges[:-1])\n",
    "    hist_ax.plot(centers, y, color=PICKER_COLORS[i], label=pckr_name)\n",
    "\n",
    "    # sample particles\n",
    "    if pckr_name in samp_xval_ranges:\n",
    "        for x_rng in samp_xval_ranges[pckr_name]:\n",
    "            # only take n_samp particles\n",
    "            n_particles_added = 0\n",
    "            samples[pckr_name][x_rng] = []\n",
    "            for i in range(len(class_avgs[pckr_name][\"mrcs\"])):\n",
    "                if n_particles_added >= n_samp:\n",
    "                    break\n",
    "                mrc = class_avgs[pckr_name][\"mrcs\"][i]\n",
    "                score_idx = class_avgs[pckr_name][\"idxs\"][i]\n",
    "                score = maxes[score_idx]\n",
    "                if score >= x_rng[0] and score <= x_rng[1]:\n",
    "                    samples[pckr_name][x_rng].append({\"mrc\": mrc, \"score\": score})\n",
    "                    n_particles_added += 1\n",
    "\n",
    "hist_ax.set_xlabel(\"Correlation\")\n",
    "hist_ax.set_ylabel(\"Frequency\")\n",
    "hist_ax.legend(loc=\"best\", frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot sample grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 7200x4800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot sample grid\n",
    "if not samp_xval_ranges:\n",
    "    exit(0)\n",
    "\n",
    "n_samp_grids = len(samp_xval_ranges.keys())\n",
    "samp_fig = plt.figure(constrained_layout=True, figsize=(12, 8), dpi=600)\n",
    "n_rows = sum(len(v) for v in samp_xval_ranges.values())\n",
    "samp_gs = samp_fig.add_gridspec(nrows=n_rows, ncols=n_samp + 1)\n",
    "pckr_offset = 0\n",
    "for pckr_name, v in samples.items():\n",
    "    for j, (x_rng, samp_imgs) in enumerate(v.items()):\n",
    "        # add label for each row in col 0\n",
    "        ax = samp_fig.add_subplot(samp_gs[pckr_offset + j, 0])\n",
    "        ax.axis(\"off\")\n",
    "        ax.text(\n",
    "            0.5,\n",
    "            0.5,\n",
    "            f\"{pckr_name}\\n{x_rng[0]}-{x_rng[1]}\",\n",
    "            va=\"center\",\n",
    "            ha=\"right\",\n",
    "            fontsize=8,\n",
    "        )\n",
    "        # add images to each row\n",
    "        for k, img in enumerate(samp_imgs):\n",
    "            ax = samp_fig.add_subplot(samp_gs[pckr_offset + j, k + 1])\n",
    "            ax.axis(\"off\")\n",
    "            ax.imshow(img[\"mrc\"], cmap=\"gray\")\n",
    "            ax.set_title(f\"{img['score']:.3f}\", fontsize=8)\n",
    "    pckr_offset += len(v)\n",
    "plt.savefig(out_dir / \"score_hist_samples.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "55ecd66aef100623542efa30a95cc0eb9cfa9337603900e41776bd00c60e9848"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('3.7.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
